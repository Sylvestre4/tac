{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance d'entités nommées avec SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentation est accessible ici: https://spacy.io/api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time \n",
    "import spacy\n",
    "!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../data/tmp/1950_clean.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appliquer la reconnaissance d'entités nommées sur notre corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le texte\n",
    "n=1000000\n",
    "try:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()[:n] \n",
    "    print(f\"Texte chargé. Premiers 500 caractères :\\n{text[:500]}...\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erreur : Le fichier '{file_path}' n'a pas été trouvé. Veuillez vérifier le chemin.\")\n",
    "    exit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Traiter le texte\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"fr_core_news_md\") # Charger le modèle spaCy\n",
    "    print(\"\\nModèle spaCy chargé avec succès.\")\n",
    "except OSError:\n",
    "    print(\"\\nErreur : Le modèle spaCy 'fr_core_news_md' n'est pas installé.\")\n",
    "    \n",
    "    exit()\n",
    "\n",
    "# Traitement du texte\n",
    "start_time = time.time() \n",
    "doc = nlp(text)\n",
    "end_time = time.time()\n",
    "print(f\"Texte traité en {end_time - start_time:.2f} secondes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compter les entités \"Personne\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = defaultdict(int)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\" and len(ent.text) > 3:\n",
    "        people[ent.text] += 1 \n",
    "\n",
    "print(f\"\\nNombre d'entités 'Personne' uniques trouvées : {len(people)}\")\n",
    "sorted_people = sorted(people.items(), key=lambda kv: kv[1], reverse=True)\n",
    "print(\"\\n--- Top 50 des personnes les plus fréquentes ---\")\n",
    "\n",
    "# Afficher les 50 premières personnes et leurs fréquences\n",
    "for person, freq in sorted_people[:50]:\n",
    "    print(f'\"{person}\" apparaît {freq} fois dans le corpus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice: essayez de lister les lieux (LOC) et les organisations (ORG) les plus mentionnées dans le corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_entities_counts = defaultdict(lambda: defaultdict(int))\n",
    "total_entities_found = 0\n",
    "\n",
    "for ent in doc.ents:\n",
    "    categorized_entities_counts[ent.label_][ent.text] += 1\n",
    "    total_entities_found += 1\n",
    "\n",
    "print(\"\\n Résultat de l'extraction des entités nommées \")\n",
    "if total_entities_found == 0:\n",
    "    print(\"Le texte ne contient aucune entité nommée détectée par le modèle.\")\n",
    "else:\n",
    "    print(f\"Un total de {total_entities_found} entités (y compris les doublons) ont été détectées.\")\n",
    "    print(\"\\n Entités nommées qui apparaissent 2 fois ou plus \")\n",
    "\n",
    "    found_any_recurring = False\n",
    "\n",
    "    for label in sorted(categorized_entities_counts.keys()):\n",
    "        entities_in_category = [\n",
    "            (entity_text, count)\n",
    "            for entity_text, count in categorized_entities_counts[label].items()\n",
    "            if count >= 2\n",
    "        ]\n",
    "\n",
    "        if entities_in_category:\n",
    "            found_any_recurring = True\n",
    "            entities_in_category_sorted = sorted(entities_in_category, key=lambda item: item[1], reverse=True)\n",
    "\n",
    "            print(f\"\\n Catégorie : {label} ({len(entities_in_category_sorted)} entité(s) récurrente(s))\")\n",
    "            for entity_text, count in entities_in_category_sorted:\n",
    "                print(f\"- {entity_text} : apparaît {count} fois\")\n",
    "\n",
    "    if not found_any_recurring:\n",
    "        print(\"\\n Aucune entité nommée n'apparaît 2 fois ou plus dans le texte.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
